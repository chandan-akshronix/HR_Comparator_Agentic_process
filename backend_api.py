import sys, os, logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, BackgroundTasks, HTTPException
from pymongo import MongoClient
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware
from orchestrator import main_workflow
from pydantic import BaseModel
from typing import List, Dict, Any
from langchain_core.output_parsers import JsonOutputParser
import json
import time
from langgraph_flow import build_langgraph
from orchestrator import compute_stability_score, postprocess_recruiter_logic

PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

load_dotenv()
logging.basicConfig(level=logging.INFO)

MONGODB_URL = os.getenv("MONGODB_URL")
DATABASE_NAME = os.getenv("DATABASE_NAME", "hr_resume_comparator")

client = MongoClient(MONGODB_URL)
db = client[DATABASE_NAME]

app = FastAPI(title="AI Resume‚ÄìJD Matching Backend")

origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://localhost:5173",  # Vite frontend
    "http://localhost:8000"   # Main backend
]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================
# Request/Response Models
# ============================================
class BatchComparisonRequest(BaseModel):
    workflow_id: str
    jd_extracted: Dict[str, Any]  # Pre-extracted JD data from MongoDB (JobDescription collection)
    resumes: List[Dict[str, Any]]  # [{resume_id, resume_extracted}, ...]

# ============================================
# Helper Function: Process Single Resume (Async)
# ============================================
def process_single_resume(
    resume_data: dict,
    jd_extracted_str: str,
    parser: JsonOutputParser,
    app_graph,
    idx: int,
    total: int
) -> dict:
    """
    Process a single resume through Comparator agent
    This runs in parallel with other resumes
    """
    resume_id = resume_data["resume_id"]
    
    logging.info(f"‚ñ∂Ô∏è Processing resume {idx}/{total}: {resume_id}")
    logging.info(f"   ‚úÖ Using pre-extracted data (skipping 2 LLM calls)")
    
    try:
        # Prepare state with pre-extracted data
        state = {
            "jd_extracted": jd_extracted_str,
            "resume_extracted": json.dumps(resume_data["resume_extracted"])
        }
        
        # Run Comparator agent only
        result_state = app_graph.invoke(state)
        
        # Parse comparison result
        comparison_result = result_state.get("comparison_result", "")
        try:
            comp_json = parser.parse(comparison_result)
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Failed to parse comparison result: {e}")
            comp_json = {
                "fit_category": "Unknown",
                "total_score": 0,
                "selection_reason": comparison_result[:500],
                "parameter_breakdown": {},
                "risk_factors": [],
                "growth_signals": []
            }
        
        # Extract resume data
        resume_extracted_data = resume_data.get("resume_extracted", {})
        
        # Compute stability score
        stability_score, gap_flags = compute_stability_score(
            resume_extracted_data.get("Career_History", [])
        )
        comp_json["stability_score"] = stability_score
        
        # Merge risk factors
        existing_risks = comp_json.get("risk_factors", [])
        if isinstance(existing_risks, list):
            comp_json["risk_factors"] = list(set(existing_risks + gap_flags))
        else:
            comp_json["risk_factors"] = gap_flags
        
        # Apply recruiter logic
        comp_json = postprocess_recruiter_logic(comp_json)
        
        # Format result
        result = {
            "resume_id": resume_id,
            "match_score": float(comp_json.get("total_score", 0)),
            "fit_category": comp_json.get("fit_category", "Unknown"),
            "jd_extracted": {},  # Already in MongoDB
            "resume_extracted": json.dumps(resume_extracted_data),
            "match_breakdown": comp_json.get("parameter_breakdown", {}),
            "selection_reason": comp_json.get("selection_reason", ""),
            "confidence_score": 90.0 if comp_json.get("recruiter_confidence") == "High" else 70.0,
            "risk_factors": comp_json.get("risk_factors", []),
            "growth_signals": comp_json.get("growth_signals", [])
        }
        
        logging.info(f"‚úÖ Completed resume {idx}/{total}: {resume_id} (Score: {result['match_score']})")
        return result
        
    except Exception as e:
        logging.error(f"‚ùå Error processing resume {resume_id}: {e}")
        import traceback
        traceback.print_exc()
        
        # Return error result
        return {
            "resume_id": resume_id,
            "match_score": 0,
            "fit_category": "Error",
            "jd_extracted": {},
            "resume_extracted": "{}",
            "match_breakdown": {},
            "selection_reason": f"Processing error: {str(e)}",
            "confidence_score": 0,
            "risk_factors": ["Processing Error"],
            "growth_signals": []
        }

# ============================================
# NEW: Batch Comparison Endpoint (ASYNC)
# ============================================
@app.post("/compare-batch")
async def compare_batch(request: BatchComparisonRequest):
    """
    ASYNC OPTIMIZED: Batch comparison endpoint using pre-extracted data from MongoDB
    
    Processes resumes IN PARALLEL for maximum speed!
    
    Only runs Comparator agent (no extraction agents):
    - JD data pre-extracted from JobDescription collection
    - Resume data pre-extracted from resume collection
    - Only 1 Azure OpenAI API call per resume (67% cost savings!)
    - Parallel processing: All resumes processed simultaneously
    
    Performance:
    - Sequential: 4 seconds √ó 10 resumes = 40 seconds
    - Parallel: ~4-6 seconds for all 10 resumes (85% time savings!)
    
    Input:
    - jd_extracted: Pre-extracted JD data from MongoDB
    - resumes: [{resume_id, resume_extracted}] from MongoDB
    
    Output:
    - match_score, fit_category, match_breakdown for each resume
    """
    try:
        start_time = time.time()
        parser = JsonOutputParser()
        
        # Build optimized pipeline (Comparator only)
        logging.info(f"‚ö° ASYNC OPTIMIZED MODE: Using pre-extracted data from MongoDB")
        logging.info(f"   Skipping JD_Extractor and Resume_Extractor agents")
        logging.info(f"   Processing {len(request.resumes)} resumes IN PARALLEL")
        
        graph = build_langgraph()
        app_graph = graph.compile()
        
        jd_extracted_str = json.dumps(request.jd_extracted)
        
        # Process all resumes in parallel using ThreadPoolExecutor
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor(max_workers=5) as executor:
            # Create futures for all resume processing tasks
            futures = [
                loop.run_in_executor(
                    executor,
                    process_single_resume,
                    resume,
                    jd_extracted_str,
                    parser,
                    app_graph,
                    idx + 1,
                    len(request.resumes)
                )
                for idx, resume in enumerate(request.resumes)
            ]
            
            # Wait for all tasks to complete in parallel
            logging.info(f"üöÄ Starting parallel processing of {len(request.resumes)} resumes...")
            results = await asyncio.gather(*futures)
            logging.info(f"‚úÖ All {len(request.resumes)} resumes processed in parallel!")
        
        end_time = time.time()
        processing_time_ms = int((end_time - start_time) * 1000)
        
        logging.info(f"‚è±Ô∏è Total processing time: {processing_time_ms}ms ({processing_time_ms/1000:.1f}s)")
        logging.info(f"   Average per resume: {processing_time_ms/len(request.resumes):.0f}ms")
        
        return {
            "workflow_id": request.workflow_id,
            "results": results,
            "processing_time_ms": processing_time_ms,
            "resumes_processed": len(results)
        }
        
    except Exception as e:
        logging.error(f"‚ùå Batch comparison error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "service": "AI Resume Comparator Agent"
    }

@app.post("/run_workflow/{workflow_id}")
def run_workflow(workflow_id: str, background_tasks: BackgroundTasks):
    try:
        background_tasks.add_task(main_workflow, workflow_id)
        logging.info(f"üöÄ Workflow {workflow_id} started.")
        return {"message": f"Workflow {workflow_id} started successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/workflow/status/{workflow_id}")
def get_workflow_status(workflow_id: str):
    try:
        wf = db["hr_resume_comparator.workflow_executions"].find_one({"workflow_id": workflow_id}, {"_id": 0})
        if not wf:
            raise HTTPException(status_code=404, detail="Workflow not found")
        return {"status": wf.get("status"), "progress": wf.get("progress", {})}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
def root():
    return {"message": "AI Workflow Backend Connected ‚úÖ"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("backend_api:app", host="127.0.0.1", port=9000, reload=True)
